{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
=======
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
>>>>>>> refs/remotes/origin/master
    "def save_embeddings(emb, dic, filename):\n",
    "    f = open(filename, 'w')\n",
    "    for i in range(len(emb)):\n",
    "        f.write(dic[i])\n",
    "        for j in emb[i]:\n",
    "            f.write(\" \"+str(j))\n",
    "        f.write(\"\\n\")\n",
    "            \n",
    "def load_embeddings(filename):\n",
<<<<<<< HEAD
    "    dic = {}\n",
    "    f = open(filename, \"r\")\n",
    "    eof = False\n",
    "    while not eof:\n",
=======
    "    emb = {}\n",
    "    dic = dict()\n",
    "    reverse_dic = dict()\n",
    "    \n",
    "    f = open(filename, \"r\")\n",
    "    eof = False\n",
    "    id = 0\n",
    "    while not eof:\n",
    "        \n",
>>>>>>> refs/remotes/origin/master
    "        line = f.readline()\n",
    "        if line != \"\":\n",
    "            sline = line.split()\n",
    "            vec = np.float64(sline[1:])\n",
<<<<<<< HEAD
    "            dic[sline[0]] = vec\n",
    "        else :\n",
    "            eof = True\n",
    "    return dic"
=======
    "            word = sline[0]\n",
    "            #print(word)\n",
    "            #print(vec)\n",
    "            emb[id] = vec\n",
    "            dic[id] = word\n",
    "            reverse_dic[word] = id\n",
    "            id += 1\n",
    "        else :\n",
    "            eof = True\n",
    "    return emb, dic, reverse_dic"
>>>>>>> refs/remotes/origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 147,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a,b):   \n",
    "    # la distance euclidienne entre a et b\n",
    "    resultat = np.array([])\n",
<<<<<<< HEAD
    "    for vec in b:\n",
    "        resultat = np.append(resultat,[(np.sqrt(np.sum(np.power(a-vec, 2))))])\n",
=======
    "    \n",
    "    for i in range(len(b)):\n",
    "        resultat = np.append(resultat,[(np.sqrt(np.sum(np.power(a-b[i], 2))))])\n",
    "        \n",
>>>>>>> refs/remotes/origin/master
    "    return resultat\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_emb = load_embeddings(\"emb.txt\")"
=======
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb, dic, reverse_dic = load_embeddings(\"emb.txt\")"
>>>>>>> refs/remotes/origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a adapter\n",
    "\n",
    "random_word = r.choice(count)\n",
    "id_random_word = dictionary[str(random_word[0])]\n",
    "vec = usable_embeddings[dictionary[\"aragorn\"]]\n",
    "\n",
    "\n",
    "dist  = dist(vec,usable_embeddings)\n",
    "print( str(random_word[0]) + \" ---> \")\n",
    "\n",
    "mins = dist.argsort()[:10]\n",
    "imin = dist.argsort()[0]\n",
    "for i in mins:\n",
    "    print(reverse_dictionary[i])"
   ]
=======
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nClosestWords(word, n): #the dics and embeddings need to be charged already\n",
    "\n",
    "    import random as r\n",
    "    import collections\n",
    "\n",
    "    try:\n",
    "        id_word = reverse_dic[word]\n",
    "    except:\n",
    "        print(\"The chosen word doesn't exist in Lord Of The Ring. Please try something else.\")\n",
    "        return\n",
    "    vec = emb[id_word]\n",
    "\n",
    "    distances  = dist(vec,emb)\n",
    "    print( word + \" ---> \")\n",
    "\n",
    "    mins = distances.argsort()[:n]\n",
    "    #mins = np.delete(mins, 0) #we delete the minmum distance, wich is the same word\n",
    "    for i in mins:\n",
    "        print(dic[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closestWord(vec):\n",
    "    distances  = dist(vec,emb)\n",
    "    return dic[distances.argsort()[0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aIsToB(boy, son, girl): #dictionnary and embeddings must be loaded\n",
    "    #This function tries to guess the corresponding hword given a couple of words, and another one for comparison\n",
    "    # EX: \"boy\" is to \"son\" what \"girl\" is to ? => the model should guess \"daughter\"\n",
    "    \n",
    "    \n",
    "    id_boy = reverse_dic[boy]\n",
    "    id_son = reverse_dic[son]\n",
    "    id_girl = reverse_dic[girl]\n",
    "    \n",
    "    emb_boy = emb[id_boy]\n",
    "    emb_son = emb[id_son]\n",
    "    emb_girl = emb[id_girl]\n",
    "    \n",
    "    diff = emb_boy - emb_son\n",
    "    \n",
    "    guess = emb_girl + diff\n",
    "        \n",
    "    #print(guess)\n",
    "    #print(emb_son)\n",
    "    guessed_word = closestWord(emb_girl)\n",
    "    \n",
    "    print(boy + \" is to \"+ son)\n",
    "    print(\"what \" + girl + \" is to ?\")\n",
    "    print( \"==> \" +  guessed_word)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ring is to sauron\n",
      "what precious is to ?\n",
      "==> precious\n"
     ]
    }
   ],
   "source": [
    "aIsToB(\"ring\", \"sauron\", \"precious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> refs/remotes/origin/master
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
