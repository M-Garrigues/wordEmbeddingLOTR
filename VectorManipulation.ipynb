{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_embeddings(emb, dic, filename):\n",
    "    f = open(filename, 'w')\n",
    "    for i in range(len(emb)):\n",
    "        f.write(dic[i])\n",
    "        for j in emb[i]:\n",
    "            f.write(\" \"+str(j))\n",
    "        f.write(\"\\n\")\n",
    "            \n",
    "def load_embeddings(filename):\n",
    "    emb = {}\n",
    "    dic = dict()\n",
    "    reverse_dic = dict()\n",
    "    \n",
    "    f = open(filename, \"r\")\n",
    "    eof = False\n",
    "    id = 0\n",
    "    while not eof:\n",
    "        \n",
    "        line = f.readline()\n",
    "        if line != \"\":\n",
    "            sline = line.split()\n",
    "            vec = np.float64(sline[1:])\n",
    "            word = sline[0]\n",
    "            #print(word)\n",
    "            #print(vec)\n",
    "            emb[id] = vec\n",
    "            dic[id] = word\n",
    "            reverse_dic[word] = id\n",
    "            id += 1\n",
    "        else :\n",
    "            eof = True\n",
    "    return emb, dic, reverse_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a,b):   \n",
    "    # la distance euclidienne entre a et b\n",
    "    resultat = np.array([])\n",
    "    \n",
    "    for i in range(len(b)):\n",
    "        resultat = np.append(resultat,[(np.sqrt(np.sum(np.power(a-b[i], 2))))])\n",
    "        \n",
    "    return resultat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb2.txt est le meilleur embedding de 50 dimension (plus faible perte)\n",
    "emb, dic, reverse_dic = load_embeddings(\"emb2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nClosestWords(word, n): #the dics and embeddings need to be charged already\n",
    "\n",
    "    import random as r\n",
    "    import collections\n",
    "\n",
    "    try:\n",
    "        id_word = reverse_dic[word]\n",
    "    except:\n",
    "        print(\"The chosen word doesn't exist in Lord Of The Ring. Please try something else.\")\n",
    "        return\n",
    "    vec = emb[id_word]\n",
    "\n",
    "    distances  = dist(vec,emb)\n",
    "    print( word + \" ---> \")\n",
    "\n",
    "    mins = distances.argsort()[:n]\n",
    "    #mins = np.delete(mins, 0) #we delete the minmum distance, wich is the same word\n",
    "    for i in mins:\n",
    "        print(dic[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closestWord(vec):\n",
    "    #changement pour afficher les 10 plus proches de aIsToB\n",
    "    distances  = dist(vec,emb)\n",
    "    return distances.argsort()[:10]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aIsToB(boy, son, girl): #dictionnary and embeddings must be loaded\n",
    "    #This function tries to guess the corresponding hword given a couple of words, and another one for comparison\n",
    "    # EX: \"boy\" is to \"son\" what \"girl\" is to ? => the model should guess \"daughter\"\n",
    "    \n",
    "    \n",
    "    id_boy = reverse_dic[boy]\n",
    "    id_son = reverse_dic[son]\n",
    "    id_girl = reverse_dic[girl]\n",
    "    \n",
    "    emb_boy = emb[id_boy]\n",
    "    emb_son = emb[id_son]\n",
    "    emb_girl = emb[id_girl]\n",
    "    \n",
    "    diff = emb_son - emb_boy\n",
    "    \n",
    "    guess = emb_girl + diff\n",
    "        \n",
    "    #print(guess)\n",
    "    #print(emb_son)\n",
    "    guessed_word = closestWord(guess)\n",
    "    \n",
    "    print(boy + \" is to \"+ son)\n",
    "    print(\"what \" + girl + \" is to ?\")\n",
    "    print( \"==> \" )\n",
    "    for i in guessed_word:\n",
    "        print(dic[i])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aIsToB(\"have\",\"had\", \"go\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
