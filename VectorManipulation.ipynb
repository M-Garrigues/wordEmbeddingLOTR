{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_embeddings(emb, dic, filename):\n",
    "    f = open(filename, 'w')\n",
    "    for i in range(len(emb)):\n",
    "        f.write(dic[i])\n",
    "        for j in emb[i]:\n",
    "            f.write(\" \"+str(j))\n",
    "        f.write(\"\\n\")\n",
    "            \n",
    "def load_embeddings(filename):\n",
    "    emb = {}\n",
    "    dic = dict()\n",
    "    reverse_dic = dict()\n",
    "    \n",
    "    f = open(filename, \"r\")\n",
    "    eof = False\n",
    "    id = 0\n",
    "    while not eof:\n",
    "        \n",
    "        line = f.readline()\n",
    "        if line != \"\":\n",
    "            sline = line.split()\n",
    "            vec = np.float64(sline[1:])\n",
    "            word = sline[0]\n",
    "            #print(word)\n",
    "            #print(vec)\n",
    "            emb[id] = vec\n",
    "            dic[id] = word\n",
    "            reverse_dic[word] = id\n",
    "            id += 1\n",
    "        else :\n",
    "            eof = True\n",
    "    return emb, dic, reverse_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a,b):   \n",
    "    # la distance euclidienne entre a et b\n",
    "    resultat = np.array([])\n",
    "    \n",
    "    for i in range(len(b)):\n",
    "        resultat = np.append(resultat,[(np.sqrt(np.sum(np.power(a-b[i], 2))))])\n",
    "        \n",
    "    return resultat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb2.txt est le meilleur embedding de 50 dimension (plus faible perte)\n",
    "emb, dic, reverse_dic = load_embeddings(\"emb2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nClosestWords(word, n): #the dics and embeddings need to be charged already\n",
    "\n",
    "    import random as r\n",
    "    import collections\n",
    "\n",
    "    try:\n",
    "        id_word = reverse_dic[word]\n",
    "    except:\n",
    "        print(\"The chosen word doesn't exist in Lord Of The Ring. Please try something else.\")\n",
    "        return\n",
    "    vec = emb[id_word]\n",
    "\n",
    "    distances  = dist(vec,emb)\n",
    "    print( word + \" ---> \")\n",
    "\n",
    "    mins = distances.argsort()[:n]\n",
    "    #mins = np.delete(mins, 0) #we delete the minmum distance, wich is the same word\n",
    "    for i in mins:\n",
    "        print(dic[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closestWord(vec):\n",
    "    #changement pour afficher les 10 plus proches de aIsToB\n",
    "    distances  = dist(vec,emb)\n",
    "    return distances.argsort()[:10]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aIsToB(boy, son, girl): #dictionnary and embeddings must be loaded\n",
    "    #This function tries to guess the corresponding hword given a couple of words, and another one for comparison\n",
    "    # EX: \"boy\" is to \"son\" what \"girl\" is to ? => the model should guess \"daughter\"\n",
    "    \n",
    "    \n",
    "    id_boy = reverse_dic[boy]\n",
    "    id_son = reverse_dic[son]\n",
    "    id_girl = reverse_dic[girl]\n",
    "    \n",
    "    emb_boy = emb[id_boy]\n",
    "    emb_son = emb[id_son]\n",
    "    emb_girl = emb[id_girl]\n",
    "    \n",
    "    diff = emb_son - emb_boy\n",
    "    \n",
    "    guess = emb_girl + diff\n",
    "        \n",
    "    #print(guess)\n",
    "    #print(emb_son)\n",
    "    guessed_word = closestWord(guess)\n",
    "    \n",
    "    print(boy + \" is to \"+ son)\n",
    "    print(\"what \" + girl + \" is to ?\")\n",
    "    print( \"==> \" )\n",
    "    for i in guessed_word:\n",
    "        print(dic[i])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aPlusB(a, b):\n",
    "    id_a = reverse_dic[a]\n",
    "    id_b = reverse_dic[b]\n",
    "    \n",
    "    emb_a = emb[id_a]\n",
    "    emb_b = emb[id_b]\n",
    "    \n",
    "    new_emb = emb_a + emb_b\n",
    "    \n",
    "    guessed_word = closestWord(new_emb)\n",
    "    \n",
    "    print(a +\" + \"+b+\" ==> \")\n",
    "    \n",
    "    for i in guessed_word:\n",
    "        print(dic[i])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "feat_cols = range(50) #SIZE OF THE EMBEDDINGS\n",
    "\n",
    "feat_index = [dic[i] for i in range(len(dic))]\n",
    "\n",
    "embeddings = [emb[i] for i in range(len(emb))]\n",
    "\n",
    "df = pd.DataFrame(embeddings, index = feat_index, columns=feat_cols)\n",
    "\n",
    "#Creation of the dataFrame containing the embeddings, indexed by their corresponding String."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWords(listWords):\n",
    "    \n",
    "    words = [listWords[i] for i in range(len(listWords))]\n",
    "\n",
    "    dfc = df.loc[words].copy()\n",
    "\n",
    "    if len(dfc) < 300:\n",
    "        tsne = PCA(n_components=2)\n",
    "    else:\n",
    "        tsne = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    tsne_results = tsne.fit_transform(dfc)\n",
    "    dfc['x-tsne'] = tsne_results[:,0]\n",
    "    dfc['y-tsne'] = tsne_results[:,1]\n",
    "    #print(dfc.head())\n",
    "\n",
    "    fig = plt.figure(figsize=(20,15), dpi=800)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "    for i in range(len(dfc)):\n",
    "        ax.scatter(\n",
    "            x=dfc.iloc[i][\"x-tsne\"], \n",
    "            y=dfc.iloc[i][\"y-tsne\"],\n",
    "            alpha=0.9,\n",
    "        )\n",
    "        ax.text(\n",
    "            x=dfc.iloc[i][\"x-tsne\"],\n",
    "            y=dfc.iloc[i][\"y-tsne\"],\n",
    "            s=dfc.index[i],\n",
    "            alpha=0.9,\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_pairs(word_pairs):\n",
    "\n",
    "    words = [w for pair in word_pairs for w in pair]\n",
    "    #words = [\"aragorn\",\"arathorn\",\"gimli\",\"stone\",\"gloin\",\"cheese\",\"duck\",\"log\"]\n",
    "    print words\n",
    "    dfs = df.loc[words].copy()\n",
    "    \n",
    "    tsne = PCA(n_components=2)\n",
    "    results = tsne.fit_transform(dfs.iloc[:,:100])\n",
    "    dfs['x'] = results[:,0]\n",
    "    dfs['y'] = results[:,1]\n",
    "\n",
    "    fig = plt.figure(figsize=(17,5), dpi=300)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    colors = plt.cm.tab10.colors\n",
    "    for i in range(len(dfs)):\n",
    "        ax.scatter(\n",
    "            x=dfs.iloc[i][\"x\"],\n",
    "            y=dfs.iloc[i][\"y\"],\n",
    "            alpha=0.9,\n",
    "            c=colors[i%10]\n",
    "        )\n",
    "        ax.text(\n",
    "            x=dfs.iloc[i][\"x\"],\n",
    "            y=dfs.iloc[i][\"y\"],\n",
    "            s=dfs.index[i],\n",
    "            color=colors[i%10]\n",
    "        )\n",
    "\n",
    "    for pair in word_pairs: \n",
    "        w1, w2 = pair\n",
    "        w1x, w1y = dfs.loc[w1][\"x\"], dfs.loc[w1][\"y\"]\n",
    "        w2x, w2y = dfs.loc[w2][\"x\"], dfs.loc[w2][\"y\"]\n",
    "        vec = np.array([[w1x, w1y, w2x-w1x, w2y-w1y]])\n",
    "        X, Y, U, V = zip(*vec)\n",
    "        ax.quiver(X, Y, U, V, angles='xy', scale_units='xy', scale=1, width=0.002, color=colors[0])    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aIsToB(\"is\",\"was\", \"go\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aPlusB(\"aragorn\", \"father\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "guessed_word = closestWord(emb[reverse_dic[\"galadriel\"]])\n",
    "for i in guessed_word:\n",
    "        print(dic[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotWords([dic[i] for i in range(299)])\n",
    "\n",
    "#plotWords([\"aragorn\",\"arathorn\",\"gimli\",\"stone\",\"gloin\",\"cheese\",\"duck\",\"log\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_pairs([(\"aragorn\", \"arathorn\"), (\"gimli\", \"gloin\"),(\"heir\", \"father\")])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
